

주키퍼랑 관련

CAP 이론

일관성, 가용성
분할내부성(포기)



https://velog.io/@attosisss_/리눅스-에서-1024-이하-포트-사용하기

https://was-master.tistory.com/6


https://kafka.apache.org/39/javadoc/org/apache/kafka/common/security/auth/SecurityProtocol.html


3대 이상을 사용하는 이유

https://2kindsofcs.tistory.com/79
데이터의 두 복사본을 사용할 때, 두 데이터가 서로 다를 경우 어느 버전을 선택할까요?
세 번째 데이터가 타이브레이커(tie breaker) 역할을 합니다.
왜 데이터가 다를 수 있을까요?
한 컴퓨터가 잠시 다운되었거나 서로 통신할 수 없는 상황에서는, 시스템이 쓰기 작업을 중단하지 않는 한 데이터가 서로 다를 가능성이 있습니다. 그러나 세 대의 컴퓨터를 사용하는 경우, 한 대가 다운되거나 다른 컴퓨터와 분리되더라도 나머지 두 대는 데이터가 일관성을 유지하면서 데이터를 수락할 수 있습니다. (물론 상관된 장애(correlated failures)가 발생할 가능성도 있으므로 이를 대비해야 합니다.)

업데이트: 분산 알고리즘의 일반적인 동작 원리
대부분의 분산 알고리즘은 쓰기를 보장하기 위해 쿼럼(quorum) 기반 시스템을 사용합니다. 대부분의 경우, 단순한 과반수(majority) 기준을 사용하며, 이는 최소한 ceil(n/2) 노드가 값을 저장해야 데이터가 내구성 있게 기록된다는 것을 의미합니다.
값이 쿼럼에 도달한 후에는 다른 쿼럼을 구성할 수 없기 때문에, 그 값을 다시 무효화하거나 덮어쓸 수 없게 됩니다.
두 노드 시스템:
ceil(n/2) = 2이기 때문에, 한 노드가 다운되면 더 이상 쓰기를 허용할 수 없습니다.
세 노드 시스템:
ceil(n/2) = 2이므로, 한 노드가 다운되더라도 시스템은 여전히 쓰기를 허용할 수 있습니다.

결론적으로 이는 내구성(durability) vs 비용(cost) vs 지연(latency)의 문제입니다.
노드가 많아질수록 데이터 손실 가능성은 줄어듭니다.
한 개의 노드는 매우 휘발성입니다.
두 개의 노드는 조금 더 나은 내구성을 가집니다.
세 개의 노드는 상당히 신뢰할 만한 수준입니다. 많은 시스템이 여기에서 멈춥니다.
그러나 더 높은 내구성이 필요한 시스템은 5개, 7개, 또는 9개의 노드가 필요합니다.

실제 사례: 높은 신뢰성이 필요한 시스템
제가 일하는 인터넷에서 가장 신뢰성이 높은 시스템 중 하나는 5개의 노드를 쿼럼에 사용하며, 최대 16개의 핫 백업 노드를 추가로 운영합니다.
우리의 경우, 비용은 내구성 요구 사항에 비해 크지 않으며, 5개의 노드를 쿼럼으로 사용하는 이유는 지연(latency)을 줄이기 위함입니다.
추가 백업 노드는 약간의 내구성 향상과 쿼럼의 읽기 부하를 분산시키는 데 사용됩니다.
https://tech.kakao.com/posts/484


log.retention.ms는 로그 파일이 저장된 시간을 기준으로, 지정된 시간 이후에 자동으로 삭제하는 설정입니다.
기본적으로는 Kafka에서 설정된 보존 기간을 초과한 메시지들이 삭제됩니다.
무한 보존을 위해서는 이 값을 **-1**로 설정하면 됩니다. 이렇게 설정하면 Kafka는 로그를 무기한으로 보존하게 됩니다.

하드웨어 부분 보충 필요
https://kafka.apache.org/documentation/#hwandos



