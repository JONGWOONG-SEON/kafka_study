
# chapter02 카프카 설치하기

## **2.3 브로커 설정하기**

### **2.3.1 핵심 브로커 매개변수**

#### **1. broker.id**

- 모든 카프카 브로커는 정숫값 식별자를 갖는데, 그 값은 broker.id로 설정이 가능함
- 기본 값은 0이지만 어떤 값도 될 수 있다.

#### **2. listeners**

- listeners는 Kafka 브로커가 클라이언트(Producer, Consumer) 및 다른 브로커와 통신하기 위해 사용하는 네트워크 인터페이스와 프로토콜 설정을 정의하는 구성 옵션
- 이 설정은 Kafka 브로커가 어떤 네트워크 주소와 포트를 통해 클라이언트 요청을 수신할지를 결정함
- 리스너는 {프로토콜}://{호스트 이름}:{포트}의 형태로 정의됨
- 유효한 listener 설정의 예로는 PLAINTEXT://localhost:9092,SSL://9091가 있다.

#### **3. zookeeper.connect**

- 브로커의 메타 데이터가 저장되는 주키퍼의 위치를 가리킴
- 로컬호스트의 2181번 포트에서 작동 중인 주키퍼를 사용할 경우 localhost:2181로 잡아주면 됨

#### **4. log.dirs**

- 카프카는 모든 메시지를 로그 세그먼트(log segment)단위로 묶어서 log.dir 설정에 지정된 디스크 디렉토리에 저장함.
- 다수의 디렉토리를 지정하고자 할 경우, log.dirs를 사용하는 것이 좋다.
- log.dirs는 쉼표로 구분된 로컬 시스템 경로의 목록이다.

#### **5. num.recovery.threads.per.data.dir**

- 브로커가 시작할 때 데이터 복구 작업에 사용되는 스레드 수
  - num.recovery.threads.per.data.dir = 8이라면, 각 데이터 디렉토리에서 최대 8개의 스레드를 사용해 복구 작업을 수행
  - 디렉토리의 수 log.dirs = 3이라면, 총 스레드 수는 8 * 3 = 24개 이다.

#### **6. auto.create.topics.enable**

- auto.create.topics.enable은 클라이언트(Producer, Consumer)가 존재하지 않는 토픽을 요청할 때, 자동으로 토픽을 생성할지 여부를 결정하는 설정
  - 기본값: true
  - 설정이 활성화(true)되어 있으면 Producer나 Consumer가 특정 토픽에 접근하려고 할 때, 해당 토픽이 존재하지 않으면 Kafka 브로커가 자동으로 토픽을 생성함
  - 설정이 비활성화(false)되어 있으면 Producer나 Consumer가 특정 토픽에 접근하려고 할 때, 해당 토픽이 존재하지 않더라도 Kafka 브로커가 자동으로 토픽 생성하지 않음.

#### **7.auto.leader.rebalance.enable**

- 모든 토픽의 리더 역할이 하나의 브로커에 집중됨으로써 카프카 클러스터의 균형이 깨지는 수가 있다.
- 이 설정을 활성화해주면 가능한 한 리더 역할이 균등하게 분산되도록 함으로써 이러한 사태가 발생하는 것을 방지할 수 있다.

```
# controller가 리더 파티션의 불균형을 확인하는 주기
# 기본값: 300초 (5분)

leader.imbalance.check.interval.seconds = 300
```

```
# 브로커 간 리더 파티션 불균형이 허용되는 최대 비율
# 기본값 10%
leader.imbalance.per.broker.percentage = 5
```

- leader.imbalance.per.broker.percentage에 설정된 값을 넘어가면 파티션의 선호 리더 리밸런싱이 발생한다.

#### **8.delete.topic.enable**

- 클러스터의 토픽을 임의로 삭제하지 못하게끔 막아줌

```
# 임의 삭제 가능
delete.topic.enable = true

# 임의 삭제 불가능
delete.topic.enable = false
```

### **2.3.2 토픽별 기본값**

- 카프카 브로커 설정은 새로 생성되는 토픽에 적용되는 수많은 설정의 기본값 역시 지정한다.


#### **1. num.partitions**

- num.partitions는 토픽을 생성할 때 해당 토픽에 포함될 partition의 기본 개수를 정의하는 설정
- partition이란?
  - 파티션은 Kafka에서 데이터를 물리적으로 분산하여 저장하는 단위
  - 각 파티션은 순차적인 메시지 로그를 포함하며, 메시지에는 고유한 오프셋(offset)이 부여됨
  - 데이터는 라운드 로빈 방식 또는 특정 파티션 키를 기반으로 파티션에 저장됨

```
# num.partitions =3으로 설정되어 있으면, 아래 명령으로 생성된 토픽은 3개의 파티션을 가짐.

kafka-topics.sh --create --bootstrap-server localhost:9092 --topic example-topic

```

#### **2. default.replication.factor**

- 자동 토픽 생성 기능이 활성화되어 있을 경우, 이 설정은 새로 생성되는 토픽의 복제 팩터를 결정한다.
- 복제 팩터 값은 min.insync.replicas 설정값보다 최소한 1이상 크게 잡아줄 것을 강력히 권장한다.
- 좀 더 내고장성(fault tolerance)있는 설정을 바란다면, min.insync.replicas 설정값보다 2 큰값으로 복제 팩터를 설정하는 게 좋다. 이렇게 함으로써 유지관리와 장애 대응이 쉬워진다.

#### **3.log.retention.ms**

- log.retention.ms는 토픽에 저장된 메시지가 브로커에서 얼마나 오랫동안 보관될 지를 결정하는 설정임
- 이 설정은 Kafka의 데이터 보존 정책(retention policy)중 하나임.
- log.retention.hours, log.retention.minutes, log.retention.ms가 있으며 log.retention.ms를 사용할 것을 권장함

```
#보존 기간을 1시간(3600000ms)으로 설정
log.retention.ms = 3600000
```

#### **4. log.retention.bytes**

- 메세지 보존을 시간 외에 크기 기준으로 제어할 수 있는데 그때 사용함
- 특정 파티션의 데이터 크기가 설정 값을 초과하면 가장 오래된 메시지가 삭제됨

```
# 만약 8개의 파티션을 가진 토픽에 log.retention.bytes 설정값이 1GB로 잡혀있다면, 토픽의 최대 저장 용량은 8GB가 됨
log.retention.bytes = 1073741824 #1GB

```
#### **5. log.segment.bytes**

- 로그 세그먼트 파일의 최대 크기를 지정함.
- 세그먼트가 이 크기에 도달하면 새로운 세그먼트가 생성됨.

#### **6. log.roll.ms**

- 로그 세그먼트 파일이 닫히는 시점을 제어하는 또 다른 방법은 파일이 닫혀야 할 때까지 기다리는 시간을 지정하는 log.roll.ms 매개변수를 사용하는 것임.

#### **7. min.insync.replicas**

- 레플리카(Replica)란?
  - Kafka에서 레플리카는 파티션 데이터를 복제한 사본을 의미함.
  - Kafka는 데이터를 고가용성과 내결함성을 제공하기 위해 리더-팔로워(Leader-Follower)구조를 사용함.

- ISR(In-Sync Replica)란?
  - ISR(In-Sync Replica)는 현재 리더와 동기화된 상태의 레플리카 목록임.

- min.insync.replicas란?
  - 프로듀서(Producer)가 데이터를 성공적으로 쓰기(ack, acknowledgment) 위해 필요한 최소 ISR 레플리카 수를 지정함.
  - 이 설정은 데이터 손실을 방지하고 내결함성을 보장함.
  - acks = all: ISR에 있는 모든 레플리카로 데이터가 복제되었을 때 응답.
  - acks=1: 리더에만 데이터가 쓰이면 응답
  - acks=0: 응답을 기다리지 않음.

- 데이터 지속성 위주로 클러스터를 설정할 때, min.insync.replicas를 2로 잡아주면 최소한 2개의 레플리카가 최신 상태로 프로듀서와 동기화되도록 할 수 있다.

```
min.insync.replicas=2
```

#### **8. message.max.bytes**

- 카프카 브로커는 쓸 수 있는 메시지의 최대 크기를 제한함.
- 이것은 message.max.bytes 매개 변수에서 설정하며, 기본값은 1000000(=1MB)이다.

## **2.4 하드웨어 선택하기**

### **2.4.1 디스크 처리량**

- 로그 세그먼트를 저장하는 브로커 디스크의 처리량은 프로듀서 클라이언트의 성능에 가장 큰 영향을 미친다.
- 카프카에 메시지를 쓸 때 메시지는 브로커의 로컬 저장소에 커밋되어야 하며, 대부분의 프로듀서 클라이언트는 메시지 전송이 성공했다고 결론 내리기 전에 최소한 1개 이상의 브로커가 메시지가 커밋되었다고 응답을 보낼 때까지 대기하게 된다.

### **2.4.2 디스크 용량**

- 필요한 디스크 용량은 특정한 시점에 얼마나 많은 메시지들이 보존되어야 하는지에 따라 결정된다. 
- 만약 브로커가 하루에 1TB의 트래픽을 받을 것으로 예상되고, 받은 메시지를 1주일간 보존해야 한다면, 브로커는 로그 세그먼트를 저장하기 위한 저장 공간이 최소한 7TB가 필요할 것이다.
- 여기에 트래픽의 변동이나 증가를 대비한 예비 공간, 저장해야 할 다른 파일도 감안해서 최소 10%가량의 오버헤드를 고려해야 한다.

### **2.4.3 메모리**

- 카프카 컨슈머는 프로듀서가 막 추가한 메시지를 바로 뒤에서 쫓아가는 식으로 파티션의 맨 끝에서 메시지를 읽어 오는 것이 보통이다.
- 이러한 상황에서, 최적의 작동은 시스템의 페이지 캐시에 저장되어 있는 메시지들을 컨슈머가 읽어오는 것이 된다. 
- 따라서, 시스템에 페이지 캐시로 사용할 수 있는 메모리를 더 할당해 줌으로써 컨슈머 클라이언트 성능을 향상시킬 수 있다.

### **2.4.4 네트워크**

- 사용 가능한 네트워크 대역폭은 카프카가 처리할 수 있는 트래픽의 최대량을 결정함

### **2.4.5 CPU**

- 카프카 클러스터를 매우 크게 확장하지 않는 한, 처리능력은 디스크나 메모리 만큼 중요하지 않음
- 브로커의 전체적인 성능에 어느 정도 영향을 미침

## **2.5 클라우드에서 카프카 사용하기**

## **2.6 카프카 클러스터 설정하기**

- 여러 대의 브로커를 하나의 클러스터로 구성하는 것에는 많은 이점이 있다.
  - 가장 큰 이점은 부하를 다수의 서버로 확장할 수 있다는 점
  - 그다음 이점으로 복제를 사용함으로써 단일 시스템 장애에서 발생할 수 있는 데이터 유실을 방지할 수 있다는 장점도 있음.


### **2.6.1 브로커 개수**

- 가장 먼저 고려할 요소는 필요한 메시지를 저장하는 데 필요한 디스크 용량과 단일 브로커가 사용할 수 있는 저장소 용량
- 만약 클러스터가 10TB의 데이터를 저장하고 있어야 하는데 하나의 브로커가 저장할 수 있는 용량이 2TB라면 클러스터의 최소 크기는 브로커 5대가 됨.

### **2.6.2 브로커 설정**

- 다수의 카프카 브로커가 하나의 클러스터를 이루게 하기 위해서 설정해줘야 하는 건 두 개뿐
  - 동일한 zookeeper.connect 설정값을 가져야 한다는 것
    - zookeeper.connect는 클러스터가 메타 데이터를 저장하는 주키퍼 앙상블과 경로를 지정함.
  - 클러스터 안의 모든 브로커가 유일한 broker.id 설정값을 가져야 한다는 것

### **2.6.3 운영체제 튜닝하기**

