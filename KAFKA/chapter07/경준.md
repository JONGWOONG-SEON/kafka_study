1.






# Processing automatic preferred replica leader


```shell
2025-01-04 22:13:30 java.lang.RuntimeException: Invalid cluster.id in: /var/lib/kafka/data/meta.properties. Expected zA5juI0ZTNSRNwsEid5NaA, but read kKcB9AACSUC8vTtRgfJ-pw
2025-01-04 22:13:30     at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:509)
2025-01-04 22:13:30     at kafka.server.KafkaServer.startup(KafkaServer.scala:257)
2025-01-04 22:13:30     at kafka.Kafka$.main(Kafka.scala:112)
2025-01-04 22:13:30     at kafka.Kafka.main(Kafka.scala)
2025-01-04 22:13:30 [2025-01-04 13:13:30,314] INFO shutting down (kafka.server.KafkaServer)
```

```shell
2025-01-05 12:34:24 [2025-01-05 03:34:24,049] INFO [Controller id=3] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-01-05 12:34:24 [2025-01-05 03:34:24,050] TRACE [Controller id=3] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-01-05 12:35:09 [2025-01-05 03:35:09,174] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
2025-01-05 12:35:09 [2025-01-05 03:35:09,177] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
2025-01-05 12:35:09 [2025-01-05 03:35:09,178] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
2025-01-05 12:35:09 [2025-01-05 03:35:09,187] INFO [Controller id=3] Shutting down broker 3 (kafka.controller.KafkaController)
2025-01-05 12:35:09 [2025-01-05 03:35:09,187] DEBUG [Controller id=3] All shutting down brokers: 3 (kafka.controller.KafkaController)
2025-01-05 12:35:09 [2025-01-05 03:35:09,187] DEBUG [Controller id=3] Live brokers:  (kafka.controller.KafkaController)
2025-01-05 12:35:09 [2025-01-05 03:35:09,188] INFO [Controller id=3 epoch=5] Sending UpdateMetadata request to brokers HashSet() for 0 partitions (state.change.logger)
2025-01-05 12:35:09 [2025-01-05 03:35:09,189] TRACE [Controller id=3] All leaders =  (kafka.controller.KafkaController)
2025-01-05 12:35:09 [2025-01-05 03:35:09,191] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)
2025-01-05 12:35:09 [2025-01-05 03:35:09,194] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProces
```


```shell
2025-01-05 12:35:17 [2025-01-05 03:35:17,203] INFO [Controller id=3] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-01-05 12:35:17 [2025-01-05 03:35:17,204] TRACE [Controller id=3] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-01-05 12:40:17 [2025-01-05 03:40:17,210] INFO [Controller id=3] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-01-05 12:40:17 [2025-01-05 03:40:17,210] TRACE [Controller id=3] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-01-05 12:45:17 [2025-01-05 03:45:17,213] INFO [Controller id=3] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-01-05 12:45:17 [2025-01-05 03:45:17,213] TRACE [Controller id=3] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)

```

```shell
2025-01-05 13:07:27 [2025-01-05 04:07:27,220] INFO [zk-broker-3-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node kafka-3:9092 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
2025-01-05 13:07:27 [2025-01-05 04:07:27,240] INFO [zk-broker-3-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node kafka-3:9092 (id: 3 rack: null) (kafka.server.NodeToControllerRequestThread)
2025-01-05 13:07:32 [2025-01-05 04:07:32,073] INFO [Controller id=3] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
2025-01-05 13:07:32 [2025-01-05 04:07:32,073] TRACE [Controller id=3] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
2025-01-05 13:07:32 [2025-01-05 04:07:32,075] DEBUG [Controller id=3] Topics not in preferred replica for broker 3 Map() (kafka.controller.KafkaController)
2025-01-05 13:07:32 [2025-01-05 04:07:32,075] TRACE [Controller id=3] Leader imbalance ratio for broker 3 is 0.0 (kafka.controller.KafkaController)
```

```markdown

**"Processing automatic preferred replica leader"**는 Kafka 브로커에서 실행되는 
Preferred Replica Leader Election (선호 복제본 리더 선출) 작업과 관련된 상황을 나타냅니다. 
이를 통해 Kafka 클러스터에서 파티션의 복제본 중 하나가 리더로 선택됩니다.
```
```markdown

```
주요 배경:
복제본과 리더:

Kafka의 각 파티션은 여러 복제본(Replica)으로 유지됩니다.
특정 파티션의 복제본 중 하나가 리더 역할을 하며 클라이언트의 읽기 및 쓰기 요청을 처리합니다.
Preferred Replica:

파티션의 리더는 특정 복제본(Preferred Replica)으로 선호되며, 이는 Kafka의 데이터 균형 정책에 따라 설정됩니다.
Automatic Preferred Replica Leader Election:

클러스터 운영 중 장애, 유지보수 또는 리소스 불균형 등으로 인해 특정 복제본이 리더로 승격될 수 있습니다.
Kafka는 주기적으로 Preferred Replica를 리더로 선출하여 클러스터의 안정성과 균형을 유지하려 합니다.
"Processing automatic preferred replica leader" 작업의 의미:
리더 재조정:

특정 복제본이 선호 복제본이 아니더라도 임시로 리더 역할을 하고 있을 수 있습니다.
이 작업은 선호 복제본을 리더로 다시 선출하여 Kafka 클러스터의 데이터를 균등하게 분산시키는 과정입니다.
자동 수행:

Kafka 브로커는 특정 이벤트(예: 클러스터 재시작, 복구, 불균형 감지 등) 발생 시 자동으로 이 과정을 수행합니다.
실행 시점:

클러스터의 리더가 불균형 상태에 있는 경우
유지보수 작업 후 복제본들이 복구된 경우
관리자가 명령을 수동으로 실행한 경우 (예: kafka-preferred-replica-election.sh 스크립트)
이 작업의 목적:
클러스터 균형 유지:

데이터와 트래픽을 균등하게 분산하여 브로커의 과부하를 방지합니다.
성능 최적화:

선호 복제본이 리더가 됨으로써 최적의 성능을 제공합니다.
복구 과정의 마무리:

장애 복구 후 리더를 올바르게 재배치하는 단계로도 작동할 수 있습니다.
로그에서 자주 보이는 이유?
클러스터가 안정되지 않거나
복제본의 헬스 체크 상태가 반복적으로 변경되고 있거나
특정 관리 작업이 진행 중일 가능성이 있습니다.
만약 이 로그가 과도하게 출력된다면:

복제본 상태 확인: 모든 복제본이 정상인지 확인 (kafka-topics.sh --describe)
네트워크 지연: 브로커 간 네트워크 연결 상태 점검
리더 선출 정책 검토: Kafka 설정에 따라 자동 선출이 자주 발생할 수 있습니다.

```