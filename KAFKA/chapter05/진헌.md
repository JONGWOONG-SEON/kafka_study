---
title: "[kafka]05. AdminClient"
tags:
  - kafka
published: 2024-12-08
---

## 1. Admin Client

> Kafka Admin Client는 토픽 관리, 파티션 관리, 컨슈머 그룹 관리 등 카프카 클러스터의 메타데이터를 관리하기 위한 API를 제공한다. 여기서는 Admin Client의 간단한 설계와 사용 시나리오를 살펴본다.

---

**_Concept_**

- **Kafka Admin Client** : 카프카 클러스터의 메타데이터를 관리 및 제어하기 위해 카프카에서 제공하는 인터페이스. 토픽 관리, 컨슈머 그룹, entity 설정등 기능 제공.

---

### AdminClient 설계방식

---

**_Concept_**

- **CAP Theory** : : 분산시스템 설계시 고려하는 중요 3가지 원칙. Consistency(일관성 : 모든 노드가 동시에 같은 데이터를 보여줘야 함. 노드 간 데이터 동기화가 중요 ) , Availability, Partition Tolerance로 구성됨. 핵심은 기본적으로 3가지 원칙중 2가지만 설계에서 가져갈 수 있고 시나리오에 따라 어떻게 가져가야할 지가 달라진다는 것
- **Consistency** : 일관성. 분산 시스템에서 Consistency는 기본적으로 모든 노드가 동시에 같은 데이터를 보여줘야 한다는 것을 의미한다. 노드간 동기화가 중요.
- **Availability** : 시스템이 다운되지 않는게 최우선 순위인것. 모든 요청에 대해 성공/실패와 관계없이 계속 응답을 해야한다.
- **Partition Tolerance** : 시스템을 구성하는 요소중 하나가 망가지더라도(네트워크 통신 문제 등) 시스템이 계속 동작해야 한다는 특성
- **Eventual Consistency** : 분산 데이터 스토어 하에서의 모든 노드에서의 읽기작업이 최종적으로 동일한 값을 반환하는 것을 이론적으로 보장하는 것. 고가용성을 보장해야하는 시나리오와 관련있다. 핵심은 단기적으로 일관을 잃더라도 결국에는(Eventually) 데이터 일관성을 보장하는것.
- **Strong Consistency** : 특정 한 노드에 변경이 일어나면 즉시 시스템의 모든 노드가 동일하게 동기화되는 것. 핵심은 일단 Transaction이 일어나면 일관성을 유지해야 한다는 것. Consistency를 보장해야 하는 시나리오와 관련있다. 기본적으로 어플리케이션의 확장성과 성능과 트레이드오프를 가진다. 구체적으로는 데이터의 업데이트 또는 복제 프로세스 도중에는 Lock를 통해 다른 프로세스에서 동일 데이터를 업데이트 하지 않도록 해야한다.

---

#### 1. 비동기적 동작과 최종 일관성

- 기본적으로 Future객체를 반환한다.
- **카프카 컨트롤러로부터 브로커로듸 메타데이터 전파가 비동기적으로 이루어진다.**
- AdminClient API가 반환하는 Future 객체들은 카프카 컨트롤러의 상태가 완전히 업데이트된 후에야 완료된 것으로 간주된다.
- Eventual Consistency에 의해 브로커는 모든 토픽 정보를 조회할 수 있게 되지만 그게 정확히 언제인지는 모른다.

#### 2. Option 객체

- 브로커가 AdminClient의 요청을 어떻게 처리해야 할지에 대한 세부사항을 Option 객체에 담을 수 있다.

#### 3. 수평 구조

- 모든 Admin 작업은 KafkaAdminClient에 구현되어있는 아파치 카프카 프로토콜을 사용해서 이루어진다.

## 2. Admin Client API

---

![NOTE](https://img.shields.io/badge/NOTE-red?style=for-the-badge)
**KafkaFuture**

Future는 일단 아직 완결되지 않은 어떤 결과에 대한 프록시를 의미한다.

---

## 3. 토픽 관리 기능

### 토픽

#### 1. 토픽 조회

```java

ListTopicsResult topics = adminClient.listTopics(); // Future 객체의 Wrapper
topics.names().get().forEach(System.out::println)


```

#### 2. 토픽생성

#### 3. 파티션 수 확인

#### 4. 토픽 삭제

## 4. 설정 관리

### 설정 가능한 자원

- 브로커
- 브로커 로그
- 토픽

### 설정관리 시나리오

## 5. 컨슈머 그룹 관리

### 컨슈머 그룹

재해 복구 등의 시나리오에서 쓴다

#### 1. 컨슈머 그룹 조회

#### 2. 컨슈머 그룹 수정

- 오프셋 수정 기능이 가장 유용하다.

---

![NOTE](https://img.shields.io/badge/NOTE-red?style=for-the-badge)
**Earliest 설정**

auto.offset.reset는 컨슈머 관련 중요 설정이다. 다음 3개 설정 중 하나를 가진다.

- earliest : 마지막 커밋 기록이 없을 경우, 가장 예전(낮은 오프셋) 레코드부터 처리
- latest : 마지막 커밋 기록이 없을 경우, 가장 최근(높은 오프셋) 레코드부터 처리
- none : 커밋 기록이 없을 경우

메타데이터 리프레시 과정 중에 파티션의 변경 여부(offset 등)를 파악한다.

**카프카 컨슈머에서 auto.offset.reset 설정을 반드시 Earliest로 가져가야 하는 이유는 메타데이터 리프레시 과정중에서 데이터가 유실될 가능성이 있기 때문이다**

---

## 6. 클러스터 메타데이터

어플리케이션이 연결된 클러스터에 대한 정보를 명시적으로 읽어와야 하는 경우는 드물다.

### 클러스터 메타데이터

## 7. 고급 어드민 작업

### 파티션 추가하기

- 보통 토픽이 생성될 때 파티션 수도 같이 결정된다.
- 보통 메시지들이 키를 가진 경우 같은 키를 가진 메시지는 동일한 파티션에 들어가 동일한 순서로 처리될 거라고 예상한다.
- 파티션을 추가할 경우 이와 같은 예상에서 벗어날 수 있기에 위험하다.
- 어지간 하면 안하는게 좋다.

```java

Map<String,NewPartition> newPartitions = new HashMap<>();
newPartitions.put(TOPIC_NAME, NewPartitions.increaseTo(NUM_PARTITIONS+2));
admin.createPartitions(newPartitions).all.get();

```

### 레코드 삭제

- `deleteRecords` 사용 삭제
- 호출 시점을 기준으로 더 오래된 레코드에 대해서 컨슈머가 읽지 못하도록 삭제 플래그를 거는것
- 실제로 레코드를 디스크에서 지우는 작업은 비동기적으로 일어남

### 리더 선출

---

![NOTE](https://img.shields.io/badge/NOTE-red?style=for-the-badge)
**리더 선출의 의미**

기본적으로 파티션 리더를 선출하는 이유는 크게 3가지이다.

- **1. 데이터의 읽기/쓰기 작업에 있어서 단일한 컨택 포인트 제공**
  단일 접접을 통해 데이터 일관성을 유지할 수 있으며 여러 replica에 쓰기 요청이 분산될 경우 발생가능한 데이터 충돌 문제를 방지.

- **2. 고가용성 및 장애복구**
  leader에 장애가 발생하더라도 컨트롤러를 통해 다른 replica중 하나를 leader로 승격시킬 수 있다.
- **3. 성능 최적화**
  leader replica를 통해 읽기/쓰기 요청이 중앙화되기 때문에 데이터 처리와 복제 간의 작업분리가 가능.

---

---

**_Concept_**

- **preferred leader** : 각 파티션은 기본적으로 선호 리더라는 레플리카를 하나씩 가진다.
- **unclean leader** : 리더 레플리카가 사용불능인 상황에서 리더가 될 수 없는 레플리카 하나를 리더로 삼는 것. 이 경우 데이터 유실이 일어난다 (예전에 리더에 쓰여졌지만 새 리더로 복제되지 않는 데이터는 모두 유실됨)

---

### 레플리카 재할당

- 레플리카를 어떤 브로커에서 다른 브로커로 이동하는 것
- 레플리카를 추가하는 것
- 레플리카를 재할당하는 일은 기본적으로 대량의 데이터 복제를 초래하기에 네트워크 대역폭에 주의하고 복제 작업을 쓰로틀링 해줄 필요가 있다.

## 8. 테스트 하기

- MockAdminClient 클래스를 활용해 실제 카프카 클러스터를 돌려 어드민 작업을 수행할 필요 없이 어플리케이션이 제대로 동작하는지 확인할 수 있다.

## Takeaway

---

**_Key Takeaway_**

- 모든 Admin 작업은 KafkaAdminClient에 구현되어있는 아파치 카프카 프로토콜을 사용해서 이루어진다.
- MockAdminClient 클래스를 활용해 실제 카프카 클러스터를 돌려 어드민 작업을 수행할 필요 없이 어플리케이션이 제대로 동작하는지 확인할 수 있다.Consistency
- **카프카 컨슈머에서 auto.offset.reset 설정을 반드시 Earliest로 가져가야 하는 이유는 메타데이터 리프레시 과정중에서 데이터가 유실될 가능성이 있기 때문이다**

---

## References

- 카프카 핵심가이드
