# Chapter5

---
    AdminClient 사용 목적 
    1. 클라이언트 레벨에서 토픽을 생성해야 할 때
    2. 임베딩 기기에 요청에 동적으로 토픽을 생성해야 할 때
```java
// 토픽이 없을 때 consume 하면 나오는 에러
[kafka-producer-network-thread | producer-1] (org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.handleSuccessfulResponse:1119)  
- [Producer clientId=producer-1] Error while fetching metadata with correlation id 3 : {dev.pintel.simul.org.vehicle.json=UNKNOWN_TOPIC_OR_PARTITION}
```
- 토픽이 생성되지 않았을 때 `auto.create.topics.enable=True` 옵션으로 해결 할 수도 있지만   
  성능하락에 요인이 된다.
- Admin Client 를 사용하여 토픽을 확인하고, 생성을 통해 보다 안정적인 성능을 기대할 수 있다.
  - 토픽을 자동생성하게 되면 properties 를 통해 replica, partition 수가 결정되기 때문 
- 서적에 기술된 내용으로는 상기와 같은 장점을 가진다.

---
### 추가의견
- AdminClient 이점
  ```
  세상에 완전한 소프트웨어는 없듯이 카프카 또한 메타데이터 손상에 의한 장애가 날 수 있다.
  주키퍼 자체에 문제가 생겼을 떄는 전체 복구 절차를 진행하면 되지만, 피해 범위가 일부 토픽에 한정 되었을 경우
  장애 토픽을 빠르게 복구 할 수 있다는 장점이 있다.
  ```
- AdminClient 단점
  ```
  CLI는 브로커,주키퍼 와 요청-응답에 프로세스를 거치지만
  AdminClient 는 컨트롤러 브로커에 의존하여 설정 확인-요청-수행-동기화 순으로 프로세스가 진행되기 떄문에
  대규모 토픽관리에선 제한점이 있다.
  ```
- `auto.create.topics.enable=True` 옵션을 사용해야하는 상황?
  ```
  크롤링 어플리케이션을 통해 추가 가치를 창출해야하는 서비스
  ```
--- 

## AdminClient 메서드

- 비동기 처리
- 브로커 컨트롤러로 요청
  - AdminClient의 메서드는 브로커 컨트롤러에게 요청을 보냄 
- Future 객체 리턴
  - 1개 이상의 Future 객체를 반환하며 이 때 Future는 비동기 작업의 결과를 리턴한다.
- 메서드별 특정 옵션 객체가 존재
  - timeoutMs 파라미터는 모든 메서드에 존재
- 클러스터의 상태를 변경하는 작업은 컨트롤러에 의해 수행되며, 상태 확인은 부하가 적은 브로커로 전달

## AdminClient 객체 생성

```java
import java.util.Properties;
import org.apache.kafka.clients.admin.AdminClient;

Properties props = new Properties();
props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,"localhost:9092");
AdminClient admin = AdminClient.create(props);
admin.close(Duration.ofSeconds(30));
```
- close 요청에 경우 진행중인 작업이 수행될 때 까지 대기함
  - timeoutMs 옵션을 주게 되면 timeout이 발생하면 진행중인 작업을 종료 시킨다.
---
### DNS 옵션 설정
- DNS 별칭 사용
  - 부트스트랩 서버 설정에서 각 개 지정할 수 있으나 관리 코스트가 상승
  - `clinet_dns.lookup=reslove_canonical_bootstrap_severs_only`
  - 해당 설정을 통해 클라이언트 DNS 별칭을 flatten 하게 설정 할 수 있다.
- DNS 별칭 사용 Load Balancer 구성 시
  - 로드 밸런서에 다중 IP 주소 연결 시 변경 IP 주소를 Trace 할 수 없는 문제
  - 클라이언트 측에서 HA 환경을 사용 할 수 있도록 `client_dns.lookup=use_all_dns_ips` 설정을 해주어야 한다.
---
## 토픽 관리 기능

#### 클러스터 내 토픽 목록 확인
```java
import org.apache.kafka.clients.admin.ListTopicsResult;

ListTopicsResult topics = admin.listTopics();
topics.names().get().forEach(system.out::println);
```
- 토픽 메서드를 통해 토픽 조회, 생성, 삭제가 가능하다.

#### 클러스터 내 토픽 목록을 확인 후 없으면 생성하는 경우
```java
TopicDescription topicDescription; // 토픽 목록 확인
ListTopicsResult topics = adminClient.listTopics(); // Future 객체들을 ListTopicsResult 객체 리턴
topics.names().get().forEach(System.out::println);
DescribeTopicsResult sampleTopic = adminClient.describeTopics(TOPIC_LIST); // #1)
  try {
      topicDescription = sampleTopic.values().get(TOPIC_NAME).get(); // #2)
      log.info("Description of sample topic: {}", topicDescription);
  
      if (topicDescription.partitions().size() != NUM_PARTITIONS) { // #3)
      log.error("Topic has wrong number of partitions: {}", topicDescription.partitions().size());
      }
  } catch (ExecutionException e) { // #4) 토픽이 존재하지 않은 경우에 대한 처리
  // 모든 예외에 대해 바로 종료
  if (!(e.getCause() instanceof UnknownTopicOrPartitionException)) {
  log.error(e.getMessage());
  throw e;
}
// 토픽이 오지 않았을 때
log.info("Topic {} does not exist. Going to create it now.", TOPIC_NAME);
        
CreateTopicsResult newTopic =
adminClient.createTopics(
        List.of(new NewTopic(TOPIC_NAME, NUM_PARTITIONS, REPLICATION_FACTOR))); // #5)

    if (newTopic.numPartitions(TOPIC_NAME).get() != NUM_PARTITIONS) { // #6)
log.error("Topic was created with wrong number of partitions. Exiting.");
```
---
### 1. 토픽 목록 확인 
  ```
  정확한 설정을 갖는 토픽이 존재하는지 확인하려면 확인하려는 토픽의 목록을 인자로 넣어서 
  describeTopics() 메서드 호출 리턴되는 DescribeTopicsResult 객체 안에는 
  토픽 이름을 key 로, 토픽에 대한 상세 정보를 담는 Future 객체를 value 로 하는 맵이 들어있음
  ```
---
### 2. Future 객체에 예외처리
  ```
  Future 가 완료될 때가지 기다린다면 get() 을 사용하여 원하는 결과물 (여기선 TopicDescription) 을 얻을 수 있음
  하지만 서버가 요청을 제대로 처리하면 못할 수도 있음
  (만일 토픽이 존재하지 않으면 서버가 상세 정보를 보내줄 수도 없음)
  이 경우 서버는 에러를 리턴할 것이고, Future 는 ExecutionException 을 발생시킴
  예외의 cause 에 들어있는 것이 서버가 실제 리턴한 실제 에러임
  여기선 토픽이 존재하지 않을 경우를 처리하고 싶은 것이므로 이 예외를 처리해주어야 함
  ```
---
### 3. TopicDescription 리턴
  ```
   토픽이 존재할 경우 Future 객체는 토픽에 속한 모든 파티션의 목록을 담은 TopicDescription 을 리턴함
  TopicDescription 는 파티션별로 어느 브로커가 리더이고, 어디에 레플리카가 있고, in-sync replica 가 무엇인지까지 포함함
  주의할 점은 토픽의 설정은 포함되지 않는다는 점
  ```
---
### 4. Future 객체에 예외처리
  ```
   카프카 리턴 에러를 정확히 파악하려면 ExcutionException 의 cause를 확인해야함
   이는 result 객체는 카프카가 에러응 답을 보낼 경우 ExecutionException을 발생
   AdminClient 측 리턴 객체가 Future 객체를 포함
   Future 객체는 예외를 포함하고 있기 때문이다.
  ```
---
### 5. 토픽 생성
  ``` 
  토픽이 존재하지 않을 경우 새로운 토픽 생성
  토픽 생성 시 토픽의 이름만 필수이고, 파티션 수와 레플리카수는 선택사항임
  만일 이 값들을 지정하지 않으면 카프카 브로커에 설정된 기본값이 사용됨
//CreateTopicsResult newWrongTopic =
//  adminClient.createTopics(
//    List.of(new NewTopic(TOPIC_NAME, Optional.empty(), Optional.empty())));
  ```
---
### 6. 토픽 생성 확인
  ```
   토픽이 정상적으로 생성되었는지 확인
  여기서는 파티션의 수를 확인하고 있음
  CreateTopic 의 결과물을 확인하기 위해 get() 을 다시 호출하고 있기 때문에 이 메서드가 예외를 발생시킬 수 있음
  이 경우 TopicExistsException 이 발생하는 것이 보통이며, 이것을 처리해 주어야 함
  보통은 설정을 확인하기 위해 토픽 상세 내역을 조회함으로써 처리함
  ```
---

#### 클러스터 내 토픽 삭제

```java
try {
    sampleTopic.values().get(TOPIC_NAME).get();
    System.out.println("Topic " + TOPIC_NAME + " is still around.");
} catch (ExecutionException e) {
    System.out.println("Topic " + TOPIC_NAME + " is gone.");
}
```
- 삭제, 확인 시 삭제 작업이 비동기로 이뤄저 토픽이 남아 있을 수 있음

#### 비동기적으로 토픽의 정보 조회 
- 어드민 요청이 많은 서버 개발의 경우
- 사용자 요청, 카프카로 요청 전송, 카프카 응답 시 클라이언트로 응답을 보내는게 합리적
- HTTP 서버에서 requestHandler로 요청 
- future 객체처리시 동작하는 whenComplete 호출
- 응답이 도착하면 DescribeTopicResult 가 HTTP 클라이언트에게 응답을 보냄 
```java
HttpServerOptions options = new HttpServerOptions().setLogActivity(true);
vertx.createHttpServer(options).requestHandler(req -> {
  String topic = req.getParam("topic");
  String timeout = req.getParam("timeout");
  int timeoutMs = NumberUtils.toInt(timeout, 1000);

DescribeTopicsResult demoTopic = adminClient.describeTopics(List.of(topic), new DescribeTopicsOptions().timeoutMs(timeoutMs));
demoTopic.topicNameValues().get(topic).whenComplete(
    new KafkaFuture.BiConsumer<TopicDescription, Throwable>() {
@Override
public void accept(TopicDescription topicDescription, Throwable throwable) {
  if (throwable != null) {
    log.info("got exception");
    req.response()
            .end(
                    "Error trying to describe topic "
                            + topic
                            + " due to "
                            + throwable.getMessage());
  } else {
    req.response().end(topicDescription.toString());
  }
}
});
      })
      .listen(8080);
}
```
---

### 설정 관리
- 브로커, 브로커 로그, 토픽 설정에 사용하는 객체는 ConfigResoruce
- kafka-configs.sh 를 통해 관리하는게 보통
- topic-config 예시
  ```
  {
  "data": [
    {
    "key": "compression.type",
    "value": "producer"
    },
    {
    "key": "leader.replication.throttled.replicas",
    "value": ""
    },
    {
    "key": "message.downconversion.enable",
    "value": "true"
    },
    {
    "key": "min.insync.replicas",
    "value": "1"
    },
    {
    "key": "segment.jitter.ms",
    "value": "0"
    },
    {
    "key": "cleanup.policy",
    "value": "delete"
    },
    {
    "key": "flush.ms",
    "value": "9223372036854775807"
    },
    {
    "key": "follower.replication.throttled.replicas",
    "value": ""
    },
    {
    "key": "segment.bytes",
    "value": "1073741824"
    },
    {
    "key": "retention.ms",
    "value": "604800000"
    },
    {
    "key": "flush.messages",
    "value": "9223372036854775807"
    },
    {
    "key": "message.format.version",
    "value": "3.0-IV1"
    },
    {
    "key": "max.compaction.lag.ms",
    "value": "9223372036854775807"
    },
    {
    "key": "file.delete.delay.ms",
    "value": "60000"
    },
    {
    "key": "max.message.bytes",
    "value": "1048588"
    },
    {
    "key": "min.compaction.lag.ms",
    "value": "0"
    },
    {
    "key": "message.timestamp.type",
    "value": "CreateTime"
    },
    {
    "key": "preallocate",
    "value": "false"
    },
    {
    "key": "min.cleanable.dirty.ratio",
    "value": "0.5"
    },
    {
    "key": "index.interval.bytes",
    "value": "4096"
    },
    {
    "key": "unclean.leader.election.enable",
    "value": "false"
    },
    {
    "key": "retention.bytes",
    "value": "-1"
    },
    {
    "key": "delete.retention.ms",
    "value": "86400000"
    },
    {
    "key": "segment.ms",
    "value": "604800000"
    },
    {
    "key": "message.timestamp.difference.max.ms",
    "value": "9223372036854775807"
    },
    {
    "key": "segment.index.bytes",
    "value": "10485760"
    }
    ],
  "status": 200
  }
  ```
---

## 컨슈머 그룹 관리
#### 컨슈머 그룹 목록 조회
- 컨슈머 그룹의 목록을 조회 시 `admin.listCounsumerGroups().vaild().get()` 을 사용하게 된다.
- 클러스터에서 에러 없이 출력되는 그룹만 리턴한다는 점을 주의해야한다.
- errors() 메서드를 사용하여 모든 예외를 확인 할 수 있다.
- all() 메서드는 모든 예외 중 첫 번쨰 리턴 값을 확인 할 수 있다.

#### 컨슈머 그룹 수정
- 토픽의 오프셋 값을 조정한다 하여도 컨슈머 그룹에 변경점이 전달되지 않음
- 즉 컨슈머는 `auto.offset.reset` 설정을 가지고 있지 않은 한, 기본 설정인 토픽에 맨 처음부터 읽어온다.
- 토픽의 오프셋은 컨슈머가 새로운 파티션을 할당 받거나, 새로 시작할 때 오프셋 토픽을 읽어온다.
- 시스템 장애 상황에서 복구 정책 시 유용하다기 보다 데이터 신뢰성이 떨어질 수 있는 상황에 도움이 많이 되는 기능으로 보임

---

## 고급 어드민 작업
- 사고 상황에 유용하지만, 위험한 요소

#### 토픽 파티션 추가
- 토픽의 파티션 수는 생성될 떄 결정되는 것이 보통
- 토픽 용량 한계를 늘리기 위해 파티션을 늘리는 경우는 드뭄
- 현재 작업 중인 어플리케이션과 충돌을 유의하며 사용해야함
- `NewPartitions.increaseTo(NUMBER_PARITIONS+{추가하고 싶은 파티션 수}` 로 호출해야한다.

#### 리더 선출
- 선호 리더 선출
  - 각 파티션은 선호 리더라는 레플리카를 가진다.
  - 선호 리더 레플리카를 리더로 삼을 경우 브로커 할당 리더가 균형을 이룬다.
  - 리더를 맡을 수 있지만 리더를 맡고 있지 않은 경우, 해당 레플리카를 리더로 선출
  - `auto_leader.rebalance.enable` 옵션을 True 로 할당해주어 불균형을 해소 할 수 있음
  - 혹은 electLeader() 메서드를 호출하여 할당

- 언클린 리더 선출
  - 각 유효 레플리카들이 리더를 맡을 수 없는 상황이라면 리더로 유효하지 않은 레플리카를 강제로 리더로 할당 시킬 수 있다.
  - 이 절차는 데이터 유실을 포함 할 수 있음

- electLeader() 메서드는 비동기적으로 수행되며, 모든 브로커가 새로운 상태를 갱신하기까지 시간이 걸린다
- 다수의 파티션에서 호출이 된다면, 일부 실패 할 수 도 있다.

#### 레플리카 재할당
- 레플리카의 변경, 추가, 밸런싱, 파티셔닝이 필요할 때 사용
- `admin.alterPartitionReassignments(partitionReassignments).all().get();` 메서드를 사용하여 적용 가능
- 데이터의 복제를 초래 할 수 있기에 필요 시 요청에 쿼터를 설정하여 작업을 스로틀링 해주는것이 좋음
---

## Reference
- 카프카 핵심 가이드
- https://github.com/jinhwan2/kafka-admin-server
- https://github.com/conduktor/kafka-stack-docker-compose
