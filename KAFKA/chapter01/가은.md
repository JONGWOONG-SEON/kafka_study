## 카프카 시작하기 <br>
### 데이터를 생성된 곳에서 분석할 수 있는 곳으로 옮겨야 한다 <br>
### 즉, 관심이 있는 상품에 대한 클릭이 상품 추천으로 전환되어 조금 뒤 우리에게 보여지는 식이다 <br>
### 우리가 데이터를 이동시키는 작업에 더 적은 노력을 들일수록 핵심 비즈니스에 더욱 집중할 수 있다 <br>

## 1.1 발행/구독 메시지 전달 <br>
### 전송자는 어떤 형태로든 메시지를 분류해서 보내고, 수신자는 이렇게 분류된 메시지를 구독한다. 중간에는 브로커가 있다 <br>

### 1.1.1 초기의 발행/구독 시스템 <br>
### 가운데 메시지 큐나 프로세스 간 통신 채널을 놓는 것이다 <br>
### 즉, 각각의 애플리케이션에 대해 요청을 받아 지표를 응답하는 서버를 추가해야 한다. 이러한 서버들에서 지표를 가져다 여러 목적으로 활용하는 더 많은 애플리케이션들이 추가된다. 이렇게 추가가 되면 연결을 추적하는 것은 더 힘들어진다.<br>
### ❓ 이러한 기술 부채를 어떻게 해결할까? <br>
### ❗애플리케이션으로부터 지표를 받는 하나의 애플리케이션을 만들고, 이 지푯값들을 필요로 하는 어느 시스템이든 지표를 질의할 수 있도록 해주는 서버를 제공하면 됨 <br>

### 1.1.2 개별 메시지 큐 시스템 <br>
### 로그 메시지에도 비슷한 작업을 해주고, 사용자 활동을 추적해서 추적한 정보를 기계 학습 개발자에게 제공하거나 관리자용 보고서를 생성하는데 사용해야할 수도 있다. <br>
### 이러한 경우에도 비슷한 시스템을 구성함으로써 정보의 발행자와 구독자를 분리할 수 있다 <br>
### 그림 1-4 방식을 사용하게 되면, 여전히 중복이 많고, 버그도 한계도 제각각인 다수의 데이터 큐 시스템을 유지 관리해야 한다 <br>
### 비즈니스가 확장됨에 따라 함께 확장되는, 일반화된 유형의 데이터를 발행하고 구독할 수 있는 중앙 집중화된 시스템이 필요하다 <br>

## 1.2 카프카 입문 <br>
### 아파치 카프카는 위와 같은 문제를 해결하기 위해 고안된 메시지 발행/구독 시스템이다 <br>
### 분산 커밋 로그, 분산 스트리밍 플랫폼이라고도 한다 <br>
### 카프카에 저장된 데이터는 순서를 유지한채로 지속성 있게 보관되며 결정적으로 읽을 수 있다, 또한, 데이터를 분산시켜 저장할 수 있다 <br>

### 1.2.1 메시지와 큐 <br>
### 카프카에서 데이터의 기본 단위는 메시지이다. 메세지는 단순한 바이트 배열일 뿐이고, 키라 불리는 메타데이터를 포함할 수도 있다. 키는 메시지를 저장할 파티션을 결정하기 위해 사용된다 <br>
### 가장 간단한 방법은 키값에서 일정한 해시값을 생성한 뒤 이 값을 토픽의 파티션 수로 나눴을 때 나머지 값에 해당하는 파티션에 메시지를 저장하는 것이다. 이렇게 하면 같은 키 값을 가진 메시지는 항상 같은 파티션에 저장된다 <br>
### 메시지를 배치 단위로 저장한다, 메시지를 쓸때마다 신호가 오가는 것은 오버헤드를 발생하므로, 메세지를 배치 단위로 모아서 쓴다 <br>

### 1.2.2 스키마 <br>
### 메시지를 일정한 구조로 부여하는 것이다 <br>
### JSON, XML이 있지만, 타입 처리 기능이나 스키마 버전 간의 호환성 유지 기능이 떨어져서 아파티 에이브로를 선호한다 <br>
### 에이브로는 조밀한 직렬화 형식을 제공하고 메시지 본체와 스키마를 분리하기 때문에 스키마가 변경되더라도 코드를 생성할 필요가 없다. 데이터 타이핑과 스키마 변경에 따른 상위 호환성, 하휘 호환성 역시 지원한다 <br>

### 1.2.3 토픽과 파티션 <br>
### 메세지는 토픽 단위로 분류된다. 토픽은 다시 여러 개의 파티션(=하나의 로그)으로 나뉘어진다 <br>
### 파티션은 추가만 가능하고, 맨 앞부터 제일 끛까지의 순서로 읽힌다 <br>
### 파티션은 카프카가 데이터 중복과 확장성을 제공하는 방법이다 <br>
### 스트림은 프로듀서로부터 컨슈머로의 데이터 흐름을 나타낸다 <br>

### 1.2.4 프로듀서와 컨슈머 <br>
### 프로듀소는 새로운 메시지를 생성한다. 발행자 혹은 작성자라고도 한다 <br>
### 컨슈머는 메시지를 읽는다. 구독자 혹은 독자라고도 한다 <br>
### 컨슈머는 컨슈머 그룹의 일원으로서 작동한다. 컨슈머에서 파티션으로의 대응 관계는 컨슈머의 파티션 소유권이라고도 부른다 <br>

### 1.2.5 브로커와 클러스터 <br>
### 하나의 카프카 서버를 브로커라고 한다. 브로커는 프로듀서로부터 메시지를 전달받아 오프셋을 할당한 뒤 디스크 저장소에 저장하고, 컨슈머의 파티션 읽기 요청을 처리하고, 메시지를 보내준다 <br>
### 카프카 브로커는 클러스터의 일부로서 작동한다. 하나의 브로커가 클러스터 컨트롤러의 역할을 하게 된다 <br>
### 컨트롤러는 파티션을 브로커에 할당해주거나 장애가 발생한 브로커를 모니터링 하는 등의 관리 기능을 담당한다. 파티션은 클러스터 안의 브로커 중 하나가 담당하며, 파티션 리더라고도 한다 <br>
### 브로커는 토픽에 대해 기본적인 보존 설정이 되어 있다 <br>
### 토픽에는 로그 압착 기능을 설정할 수 있는데, 이 같은 경우 키를 갖는 메시지 중 가장 최신의 것만 보존하면 된다 <br>

### 1.2.6 다중 클러스터 <br>
### 데이터 유형별 분리, 보안 요구사항을 충족시키기 위한 격리, 재해 복구를 대비한 다중 데이터 센터 <br>
### 카프카의 복제 메커니즘은 다중 클러스터 사이에서가 아닌 하나의 클러스터에서만 작동하도록 설계되었다. 이로인해 ,  데이터센터가 어디냐에 따라 결과가 달라지는 현상을 막을 수 있다 <br>
### 카프카 프로젝트는 데이터를 다른 클러스터로 복제하는 데 사용되는 미러메이커라는 툴을 포함한다. 미러 메이커도 큐로 연결된 카프카 컨슈머와 프로듀서이다 <br>

### 1.3 왜 카프카인가? <br>
### 다중 프로듀서 <br>
#### 프로듀서 클라이언트가 여러 토픽을 사용하든 하나의 토픽을 사용하든 간에 여러 프로듀서를 처리할 수 있다 <br>
#### 컨슈머 애플리케이션은 애플리케이션 별로 하나씩, 여러 개의 토픽에서 데이터를 읽어올 필요 없이 사이트의 모든 애플리케이션에 대한 페이지 뷰 스트림 하나만 읽어오면 된다 <br>
### 다중 컨슈머 <br>
#### 다수의 카프카 컨슈머는 컨슈머 그룹의 일원으로 작동함으로써 하나의 스트림을 여럿이서 나눠서 읽을 수 있다 <br>
### 디스크 기반 보존 <br>
#### 메시지를 지속성 있게 저장할 수도 있다, 즉 컨슈머들이 항상 실시간으로 데이터를 일어올 필요가 없다. 메세지는 디스크에 쓰여진 뒤 설정된 보유 규칙과 함께 저장된다 <br>
### 확장성 <br>
#### 어떠한 크기의 데이터로 쉽게 처리가 가능하다 <br>
#### 카프카 클러스터는 작동 중에도 시스템 전체의 가용성에 영향을 주지 않으면서 확장이 가능하다 <br>
#### 여러 대의 브로커로 구성된 클러스터는 개별 브로커의 장애를 처리하면서 지속적으로 클라이언트의 요청을 받아서 처리할 수 있다 <br>
#### 더 큰 복제 팩터를 설정하는 것도 가능함 <br>
### 고성능 <br>
#### 발행된 메시지가 컨슈머에게 전달될떄까지 1초도 안걸리면서 프로듀서, 컨슈머, 브로커 모두가 매우 큰 메시지 스트림을 쉽게 다룰 수 있도록 수평적으로 확장될 수도 있는 것이다 <br>
### 플랫폼 기능 <br>
#### 개발자들이 자주 하는 작업을 api와 라이브러리 형태로 사용이 가능하다 <br>
#### 카프카 커넥트는 소스 데이터 시스템으로부터 카프카로 데이터를 가져오거나 카프카의 데이터를 싱크 시스템으로 내보내는 작업을 도와준다 <br>
#### 카프카 스트림즈는 규모 가변성과 내고장성을 갖춘 스트림 처리 애플리케이션을 쉽게 개발할 수 있게 해주는 라이브러리이다 <br>
## 1. 4 데이터 생태계
### 카프카는 순환 시스템을 제공하는데, 모든 클라이언트에 대해 일관된 인터페이스를 제공하면서 다양한 인프라스트럭처 요소들 사이에 메시지를 전달하는 것이다. 메세지 스키마를 제공하는 시스템과 결합하면 프로듀서와 컨슈머는 더 이상 어떤 형태로든 결합하거나 연결될 필요가 없다 <br>
### 1.4.1 이용사례 <br>
#### 활동 추적: 사용자의 모든 활동을 하나 이상의 토픽으로 발행되어 백엔드에서 작동 중인 애플리케이션에 전달한다. 보고서를 생성하거나, 기계 학습 시스템에 데이터를 전달하거나, 검색 결과를 업데이트하거나, 사용자 경험을 위해 다른 작업을 수행할 수 있다 <br>
#### 메세지 교환: 사용자에게 알림을 보내야 하는 애플리케이션에서 활용할 수 있다 <br>
#### 지표 및 로그 수집: 애플리케이션이 정기적으로 지푯값을 카프카 토픽에 발행하면, 모니터링과 경보를 맡고 있는 시스템이 지표값들을 가져다가 사용한다. <br>
#### 커밋 로그:  데이터베이스 커밋 로그를 발행하여 실시간 변경 사항 전달 <br>
#### 스트림 처리: 데이터를 실시간으로 처리하여 분석 및 응답 <br>







