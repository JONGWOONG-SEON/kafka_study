# 카프카 내부 메커니즘
## 클러스터 멤버십
### 구성요소
1. 브로커
    - kafka 클러스터의 기본 단위
    - 고유한 ID 를 가지고 있음
2. 주키퍼 (이전 버전)
    - Kafka 의 메타데이터를 관리
    - 브로커 상태 정보 유지
    - 클러스터 멤버십 관리 및 리더 선출

## 컨트롤러
### 역할
1. 브로커 상태 관리
    - 클러스터에 새 브로커가 추가되거나 기존 브로커가 종료되면, 이를 감지하고 클러스터 업데이트
    - heartbeat 를 통해 브로커의 상태를 주기적으로 확인
2. 파티션 리더 선출
    - 각 파티션의 리더 브로커 선출
    - 리더는 프로듀서와 컨슈머의 요청을 처리하며, 클러스터 내 다른 브로커는 팔로워 역할
    - 리더 브로커가 실패하면 컨트롤러는 ISR(In-Sync Replica) 목록을 기반으로 새로운 리더 선출
3. 파티션 복제 관리
    - 각 파티션을 여러 복제본으로 관리
    - 복제 상태를 모니터링 및 복구 작업
    - 복제본을 재분배 또는 새로운 복제본을 추가
4. 클러스터 메타데이터 관리
    - Kafka 클라이언트(프로듀서, 컨슈머)와 브로커가 사용할 수 있는 메타데이터 관리

5. 컨트롤러 장애 복구
    - 단일 브로커에 의해 실행되므로, 컨트롤러 브로커가 장애를 겪을 경우 새로운 컨트롤러 선출

## KRaft (Kafka Raft Metadata Quorum)
- kafka 2.8.0부터 주키퍼를 제거하고 KRaft 가 도입되면서 컨트롤러의 역할이 변경 및 확장

### 기존 주키퍼 기반의 문제정
1. 복잡성: Kafka 클러스터와 주키퍼 클러스터 별도로 관리
2. 지연 문제: 카프카와 주키퍼의 통신 지연
3. 데이터 일관성 문제: Kafka 와 주키퍼 간의 데이터 일치 여부를 신경써야함
4. 확장성 제한: 주키퍼 노드 수 증가에 따른 성능저하 및 카프카 수평 확장에 제한

### KRaft 특징과 장점
1. 주키퍼 제거
   - 카프카가 독립적으로 메타데이터 관리
   - 카프카 클러스터만으로 배포 및 운영 가능
2. 빠른 장애 복구
   - 리더 브로커가 장애가 발생해도, 빠르게 리더 선출 가능
   - 카프카 클러스터의 가용성이 높아짐
3. 확장성 향상
   - 수백 개의 브로커를 쉽게 확장, 주키퍼의 확장성 제한이 사라짐

### KRaft 작동 방식
- 카프카 클러스터 내의 특정 브로커가 리더 역할
- 이 리더는 카프카 클러스터 내의 메타데이터 관리, 다른 브로커는 이를 팔로워로 동기화
- 메타데이터는 __cluster_metadata 라는 내부 토픽에 저장  

### KRaft 설정 예시 
>process.roles=broker,controller   
node.id=1   
controller.quorum.voters=1@localhost:9093
log.dirs=/tmp/kraft-combined-logs

- server.properties 에서 관리
- process.roles: 해당 브로커가 broker, controller 역할 수행
- controller.quorum.voters: 컨트롤러 선출을 위한 투표 구성
- log.dir: 메타데이터 및 로그 저장 위치   

## 요청 처리
### 쓰기 요청(Produce Request)
- 데이터를 카프카에 기록하는 요청
- 프로듀서가 브로커에 메시지를 보낼 때 사용

#### 요청 흐름
1. 프로듀서가 특정 토픽에 메시지 전송
2. 브로커의 리더 파티션이 요청을 수신하고 데이터를 로컬 로그에 기록
3. 리더는 데이터를 팔로워 브로커에 복제
4. 복제가 완료되면 프로듀서에 ack응답 반환

#### 주요 옵션
- acks=0 - 프로듀서가 데이터를 전송하자마자 성공으로 간주 (데이터 유실 가능성)
- acks=1 - 리더 브로커에 기록되면 성공 (기본 설정)
- acks=all - 모든 팔로워가 복제 완료 후 성공 (가장 안정적)


### 읽기 요청(Fetch Reqeust)
- 카프카에서 데이터를 읽는 요청
- 컨슈머가 브로커에서 메시지를 가져올 때 사용

#### 요청 흐름
1. 컨슈머가 브로커에 특정 토픽, 파티션의 데이터를 요청
2. 브로커는 요청된 파티션의 리더에서 데이터를 읽음
3. 데이터를 배치로 컨슈머에 반환

#### 주요 동작 방식
- 폴링 - 컨슈머는 주기적으로 poll()을 호출해 데이터를 가져옴
- 오프셋 관리 - 컨슈머는 읽은 데이터의 오프셋을 커밋하여 읽는 위치를 추적하도록 도움

### 어드민 요청 (Admin Request)
- 카프카 클러스터 및 리소스를 관리하는 요청
- AdminClient 가 사용

#### 주요 기능
- 토픽 생성 및 삭ㅈ
- 파티션 수 확장
- ACL 관리
- 클러스터 상태 조회
- 컨슈머 그룹 리벨런

| 요청 유형         | 클라이언트       | 주요 브로커 처리 | 주 대상         | 주요 동작                        | 성능 최적화 |  
|------------------|------------------|------------------|-----------------|-------------------------------|-------------|  
| **쓰기 요청**     | Producer         | 로그 저장, 복제  | 토픽의 리더 파티션 | 배치, 압축, ACK 설정              | 배치, 압축   |  
| **읽기 요청**     | Consumer         | 로그 조회        | 컨슈머 그룹       | 오프셋 관리, 폴링                | Fetch 설정  |  
| **어드민 요청**   | AdminClient      | 클러스터 관리    | 토픽, 파티션      | 토픽 생성, 상태 조회, ACL 관리   | 비동기 처리  |  

## 물리적 저장소

### 1. 로그 파일
카프카의 기본 저장소는 로그 형태   
각 토픽, 파티션에 대한 별도 로그 존재   
    - 파티션: 카프카는 데이터를 파티션 단위로 나눠서 저장. 하나의 파티션은 하나의 로그 파일   
    - 로그 세그먼트: 세그먼트 설정 값에 따라 일정 크기에 따라 나누어짐

### 2. 세그먼트 파일
세그먼트 파일은 로그 파일이 일정 크기에 도달할 때마다 생성되는 파일   

- 데이터: 각 세그먼트는 메시지 데이터를 포함, 메시지는 오프셋이라는 고유한 번호로 식별

### 3. 인덱스 파일
인덱스 파일은 세그먼트 파일 내의 메시지에 빠르게 접근할 수 있도록 도와주는 파일   
메시지의 오프셋과 그 위치 정보를 저장    
- 데이터 구조: 각 인덱스 파일은 오프셋과 파일위치 저장
- 인덱스 갱신: 메시지가 추가될 때마다 인덱스 파일이 갱신되어 메시지에 대한 정보가 갱신   



