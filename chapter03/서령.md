# chapter03 카프카 프로듀서: 카프카에 메시지 쓰기

## **3.1 프로듀서 개요**

## **3.2 카프카 프로듀서 생성하기**

- 카프카에 메시지를 쓰려면 우선 원하는 속성을 지정해서 프로듀서 객체를 생성해야 한다.

### 카프카 프로듀서 - 3개의 필수 속성값

#### **1. bootstrap.servers**

- Kafka 클러스터와 연결하기 위해 필요한 broker의 host명과 port번호를 설정함
- 예: "localhost:9092", "broker1:9092, broker2: 9092"
- 프로듀서가 처음 연결하는데 필요한 진입점 역할을 함.

#### **2. key.serializer**

- 메시지의 키(Key)를 직렬화할 때 사용되는 Serializer 클래스를 지정함.
- 키는 메시지가 어느 파티션으로 전송될 지 결정하는데 사용됨.

#### **3. value.serializer**

- 메시지의 값(Value)를 직렬화할 때 사용되는 Serializer 클래스를 지정함.
- 값은 실제 전송하려는 데이터의 내용을 담음.

#### 직렬화의 필요성 

- 키(Key), 값(Value) 데이터는 바이트 배열(byte[])로 변환해야 네트워크로 전송할 수 있음.
- TCP/IP Protocol은 Application이 전송하는 데이터를 바이트 스트림(byte stream)으로 처리함.
- 사람이 읽을 수 있는 문자열, 숫자, 객체 등의 고수준 데이터 타입은 네트워크에서 직접 전송할 수 없음.
- 따라서 네트워크로 데이터를 전송하려면 모든 데이터는 바이트 배열로 변환(직렬화)되어야 함.

- 예:
  - 문자열 "key1" → 바이트 배열 [107, 101, 121, 49] (ASCII 코드 기반)
  - 정수 123 → 바이트 배열 [0, 0, 0, 123]

```
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class KafkaProducerExample {
    public static void main(String[] args) {
    
        // 1. Properties 객체 생성
        Properties props = new Properties();

        // 2. 필수 설정 추가
        props.put("bootstrap.servers", "localhost:9092"); // 브로커 주소
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // 키 직렬화
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // 값 직렬화

        // 3. KafkaProducer 객체 생성
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);

        // 4. 메시지 생성 및 전송
        ProducerRecord<String, String> record = new ProducerRecord<>("my-topic", "key", "value");
        producer.send(record);

        // 5. 프로듀서 종료
        producer.close();
    }
}
```

### 카프카 프로듀서 - 메시지 전송 방법

#### **1. 파이어 앤 포켓(Fire and Forget)**

- 메시지를 서버에 전송만 하고 성공 혹은 실패 여부에는 신경 쓰지 않음.

#### **2. 동기적 전송(Synchronous send)**

- 카프카 프로듀서는 언제나 비동기적으로 작동함.
- 즉, 메시지를 보내면 send()메서드는 Future 객체를 리턴함.
- 하지만 다음 메시지를 전송하기 전 get() 메서드를 호출해서 작업이 완료될 때까지 기다렸다가 실제 성공 여부를 확인해야 함.

#### **3. 비동기적 전송(Asynchronous send)**

- 콜백 함수와 함께 send()메서드를 호출하면 카프카 브로커로부터 응답을 받는 시점에서 자동으로 콜백 함수가 호출된다.

## **3.3 카프카로 메시지 전달하기**

```
# 프로듀서는 ProducerRecord 객체를 받으므로 이 객체를 생성하는 것에서부터 시작
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

# ProducerRecord를 전송하기 위해 프로듀서 객체의 send메서드를 사용한다.
try{
producer.send(record);
}

# 카프카 브로커에 메시지를 전송할 때 발생하는 에러 혹은 브로커 자체에서 발생하는 에러를 무시하더라도 프로듀서가 카프카로 메시지를 보내기 전 에러가 발생할 경우 여전히 예외가 발생할 수 있다.
catch (Exception e) {
e.printStackTrace();
}

```

### **3.3.1 동기적으로 메시지 전송하기**

### **3.3.2 비동기적으로 메시지 전송하기**

- 100개의 메시지를 전송하는 데 약 1초가 걸린다. 반면, 보내야 할 메시지를 전부 전송하고 응답을 기다리지 않는다면 100개의 메시지를 전송하더라도 거의 시간이 걸리지 않을 것이다.
- 실제로 대부분의 경우 굳이 응답이 필요 없다. 카프카는 레코드를 쓴 뒤 해당 레코드의 토픽, 파티션 그리고 오프셋을 리턴하는데, 대부분의 애플리케이션에서는 이런 메타데이터가 필요 없기 때문이다.
- 메시지를 비동기적으로 전송하고도 여전히 에러를 처리하는 경우를 위해 프로듀서는 레코드를 전송할 때 콜백을 지정할 수 있도록 한다.

```

```

## **3.4 프로듀서 설정하기**


### **3.4.1 프로듀서 설정값① - client.id**

- 프로듀서와 그것을 사용하는 애플리케이션을 구분하기 위한 논리적 식별자.
- 예) IP 104.27.155.134에서 인증 실패가 자주 발생하고 있다는 것을 알 수 있음.

### **3.4.2 프로듀서 설정값② - acks**

- acks 매개변수는 프로듀서가 임의의 쓰기 작업이 성공했다고 판별하기 위해 얼마나 많은 파티션 레플리카가 해당 레코드를 받아야 하는지를 결정함.
  - acks=0일 때: 프로듀서는 메시지가 성공적으로 전달되었다고 간주하고 브로커의 응답을 기다리지 않는다.
  - acks=1일 때: 프로듀서는 리더 레플리카가 메시지를 받는 순간 브로커로부터 성공했다는 응답을 받는다.
  - acks=all일 때: 프로듀서는 메시지가 모든 인-싱크 레플리카(In-Sync Replica)에 전달된 뒤에야 브로커로부터 성공했다는 응답을 받는다.

- acks=all이 가장 안전한 형태인데, 최소 2개 이상의 브로커가 해당 메시지를 가지고 있으며, 이는 크래시가 났을 경우에도 유실되지 않기 때문이다.

### **3.4.3 프로듀서 설정값③ - 메시지 전달 시간**

- 프로듀서는 개발자 입장에서 가장 중요한 작동을 제어하기 위해 여러 설정 매개변수를 제공함.
- send()를 호출했을 때 성공 혹은 실패하기까지 얼마나 시간이 걸리는가? 
- 이것은 카프카가 성공적으로 응답을 내려보내 줄 때까지 사용자가 기다릴 수 있는 시간이며, 요청 실패를 인정하고 포기할 때까지 기다릴 수 있는 시간이기도 한다.

### **3.4.4 linger.ms**

- linger.ms 매개변수는 현재 배치를 전송하기 전까지 대기하는 시간을 결정함.
- KafkaProducer는 현재 배치가 가득 차거나 linger.ms에 설정된 제한 시간이 되었을 때 메시지 배치를 전송함,

### **3.4.5 buffer.memory**

- 프로듀서가 메시지를 전송하기 전에 메시지를 대기시키는 버퍼의 크기(메모리의 양)를 결정함.

### **3.4.6 compression.type**

- 기본적으로 메시지는 압축되지 않은 상태로 전송됨.
- 하지만 이 매개변수를 snappy, gzip, lz4 그리고 zstd중 하나로 설정하면 해당 압축 알고리즘을 사용해서 메시지를 압축한 뒤 브로커로 전송됨.

### **3.4.7 batch.size**

- 같은 파티션에 다수의 레코드가 전송될 경우 프로듀서는 이것들을 배치 단위로 모아서 한꺼번에 전송함.
- 이 매개변수는 각각의 배치에 사용될 메모리의 양을 결정함.

### **3.4.8 max.in.flight.requests.per.connection**

- 프로듀서가 서버로부터 응답을 받지 못한 상태에서 전송할 수 있는 최대 메시지의 수를 결정함.

### **3.4.9 max.request.size**

- 이 매개변수는 프로듀서가 전송하는 쓰기 요청의 크기를 결정함.

### **3.4.10 receive.buffer.bytes, send.buffer.bytes**

- 이 매개변수는 데이터를 읽거나 쓸 때 소켓이 사용하는 TCP 송수신 버퍼의 크기를 결정함.
  - 소켓(Socket)
  - TCP 송수신 

### **3.4.11 enable.idempotence**
 
- 첫 번째 브로커가 프로듀서로 응답을 보내기 전에 크래시가 났다고 생각해보자. 
- 프로듀서는 request.timeout.ms만큼 대기한 뒤 재전송을 시도하게 된다.
- 이때 새로 보내진 메시지는 이미 메시지를 받은 바 있는 새 리더 브로커로 전달되게 된다.

## **3.5 시리얼라이저(Serializor)**

- 카프카는 정숫값을 직렬화할 때 사용하는 시리얼라이저(IntegerSerializer)뿐만 아니라 ByteArray에 사용되는 시리얼라이저 등을 포함하고 있다.

### **3.5.1 커스텀 시리얼라이저**

- 카프카로 전송해야 하는 객체가 단순한 문자열이나 정숫값이 아닐 경우에는 두 가지의 선택지가 있을 수 있다.
  - 레코드를 생성하기 위해 에이브로(Avro), 스리프트(Thrift), 프로토버프(Protobuf)와 같은 범용 직렬화 라이브러리를 사용한다.
  - 사용하고 있는 객체를 직렬화하기 위한 커스텀 직렬화 로직을 작성한다.



### **3.5.2 아파치 에이브로를 사용해서 직렬화하기**

- 아파치 에이브로는 언어 중립적인 데이터 직렬화 형식임.
- 에이브로 데이터는 언어에 독립적인 스키마의 형태로 기술됨. 이 스키마는 보통 JSON형식으로 정의되며 주어진 데이터를 스키마에 따라 직렬화하면 이진 파일 형태로 결과물이 뽑혀나오는 것이 보통임.
- 에이브로는 직렬화된 결과물이 저장된 파일을 읽거나 직렬화를 할 때 스키마 정보가 별도로 주어진다고 가정하고, 보통은 에이브로 파일 자체에 스키마를 내장하는 방법을 쓴다.

기존 스키마
```
{"namespace" : "customerManagement.avro",
"type" : "record",
"name" : "Customer",
"fields" : [
  {"name":"id", "type":"int"},
  {"name":"name", "type":"string"},
  {"name":"faxNumber", "type":["null","string"], "default":"null"}
]
}
```

새로운 스키마
```
{"namespace" : "customerManagement.avro",
"type" : "record",
"name" : "Customer",
"fields" : [
  {"name":"id", "type":"int"},
  {"name":"name", "type":"string"},
  {"name":"email", "type":["null","string"], "default":"null"}
]
}
```

데이터를 읽는 쪽 애플리케이션을 전부 변경하지 않고 스키마를 변경하더라도 어떠한 예외나 에러가 발생하지 않으며, 기존 데이터를 새 스키마에 맞춰 업데이트하는 엄청난 작업을 할 필요도 없다

### **3.5.3 카프카에서 에이브로 레코드 사용하기**

- 에이브로 레코드 (Avro Record)는 Apache Avro에서 데이터를 표현하는 단위 객체입니다. Avro Record는 JSON기반의 스키마(Schema)에 정의된 데이터 구조에따라 데이터를 저장하거나 처리할 수 있는 객체를 의미함.
- 에이브로는 레코드를 읽을 때 스키마 전체를 필요로 하기 때문에 어딘가 스키마를 저장해 두기는 해야 한다. 이 문제를 해결하기 위해 스키마 레지스트리(Schema Registry)라 불리는 아키텍처 패턴을 사용한다.
- 카프카에 데이터를 쓰기 위해 사용되는 모든 스키마를 레지스트리에 저장한다는 것
- 

## **3.6 파티션**

- 우리가 생성한 ProduceRecord 객체는 토픽, 키, 밸류의 값을 포함함.
- 카프카 메시지는 키-밸류 순서쌍(key-value pair)이라고 할 수 있는데, 키의 기본값이 null인 만큼 토픽과 밸류의 값만 있어도 ProduceRecord 객체를 생성할 수 있기는 하지만 대부분의 경우 키값이 지정된 레코드를 쓴다.
- 같은 키값을 가진 모든 메시지는 같은 파티션에 저장되는 것이다.
- 즉, 임의의 프로세스가 전체 파티션 중 일부만 읽어올 경우, 특정한 키값을 갖는 모든 메시지를 읽게 된다는 것이다.

```
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Laboratory Equipment", "USA")
```


```
# 키값을 null로 잡은 경우
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "USA")
```

- 기본 파티셔너(partitioner) 사용 중에 키값이 null인 레코드가 주어질 경우, 레코드는 현재 사용 가능한 토픽의 파티션 중 하나에 랜덤하게 저장됨.
- 각 파티션별로 저장되는 메시지 개수의 균형을 맞추기 위해 라운드 로빈(round robin)알고리즘이 사용됨.

## **3.7 헤더(Header)**

- 레코드는 키값, 밸류값 외에도 헤더를 포함함.
- 레코드 헤더는 카프카 레코드의 키/밸류값을 건드리지 않고 추가 메타데이터를 심을 때 사용함. 헤더의 주된 용도 중 하나는 메시지의 전달 내역을 기록하는 것.
- 즉, 데이터가 생성된 곳의 정보를 헤더에 저장해 두면, 메시지를 파싱할 필요없이 헤더에 심어진 정보만으로 메시지를 라우팅하거나 출처를 추적할 수 있는 것.

```
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

record.headers().add("privacy-level", "YOLO".getBytes(StandardCharsets.UTF_8))
```

## **3.8 인터셉터**

- 카프카 클라이언트의 코드를 고치지 않으면서 그 작동을 변경해야 하는 경우가 있다.
- 회사 내에서 사용하는 모든 애플리케이션에 동일한 작동을 집어넣는다거나 아니면 원래 코드를 사용할 수 없는 상황이 그렇다.
- 이럴 때 사용하는 것이 카프카의 ProducerInterceptor 인터셉터다.
- 인터셉터의 일반적인 사용 사례로는 모니터링, 정보 추적, 표준 헤더 삽입 등이 있다. 특히 레코드에 메시지가 생성된 위치에 대한 정보를 심음으로써 메시지의 전달 경로를 추적하거나 민감한정보를 삭제 처리하는 등의 용도로 활용된다.

## **3.9 쿼터, 스로틀링**

- 카프카 브로커에는 쓰기/읽기 속도를 제한할 수 있는 기능이 있다. 한도(쿼터 quota)를 설정해주면 되는데, 카프카에는 다음과 같이 3가지의 쿼터 타입에 대해 한도를 설정할 수 있다.
  - 쓰기 쿼터 (produce quota)
  - 읽기 쿼터 (consume quota)
  - 요청 쿼터 (request quota)

- 쿼터는 기본값을 설정하거나, 특정한 client.id 값에 대해 설정하거나, 특정한 사용자에 대해 설정하거나 혹은 둘 다 설정하는 식으로 적용이 가능하다.
- 사용자에 대해 설정된 쿼터는 보안 기능과 클라이언트 인증 기능이 활성화되어 있는 클라이언트에서만 작동한다.

